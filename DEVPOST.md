# FirstPR â€” The Project Story

## Inspiration

It started with a `git clone` and a sinking feeling.

I remember staring at my terminal, freshly cloned repo in front of me, 347 Python files deep, and absolutely no idea where to begin. I was trying to make my **first open-source contribution**. I'd heard all the advice â€” _"just pick a good-first-issue"_ â€” but nobody told me what to do *after* that. Nobody told me how to figure out which file to touch, what the architecture actually looked like, or why there were four different config files and a `Makefile` that imported from a script that imported from another script.

The frustration was real:

```
$ find . -name "*.py" | wc -l
347

$ cat README.md
# Project
TODO: Add docs

$ cat CONTRIBUTING.md
cat: CONTRIBUTING.md: No such file or directory
```

I spent **more time understanding the codebase** than actually writing code. I'd grep for function names, trace import chains, open file after file trying to build a mental map of the architecture. The tech stack was scattered across `requirements.txt`, `package.json`, `pyproject.toml`, and a `Dockerfile` that referenced all three. Onboarding docs â€” if they existed at all â€” were three major versions behind.

Then one night, scrolling through issues on yet another unfamiliar repo, I realized: **every newcomer goes through this exact pain**. Thousands of developers want to contribute, but the barrier isn't skill â€” it's _comprehension_. Understanding a codebase is the real first PR.

I thought: _"What if I could solve this â€” not just for me, but for everyone?"_

What if you could just **paste a GitHub link** and instantly get a full, beautiful breakdown of the entire repository â€” its architecture rendered as a diagram, its file tree annotated with explanations, its issues ranked by beginner-friendliness, its community health scored, and a personalized day-by-day onboarding roadmap â€” all powered by AI?

That night, I opened a blank terminal and typed `mkdir firstpr`.

That's how **FirstPR** was born.

---

## What It Does

FirstPR is an **AI-powered repository analysis and onboarding assistant** built for the developer who just cloned a repo and doesn't know where to start. You paste a GitHub URL â€” that's it â€” and FirstPR generates a complete, interactive breakdown:

### ğŸ—ï¸ Architecture at a Glance
A **Mermaid diagram** of the project architecture generated by Gemini 3, showing how modules connect â€” the kind of diagram you'd normally have to read 20 files to draw yourself.

### ğŸ“ Interactive File Explorer with "Explain with AI"
Browse the full file tree in a sidebar. Click any file to view its source with **syntax highlighting** across 10+ languages. Hit the **"Explain with AI"** button, and Gemini 3 breaks down what the file does, why it exists, and how it fits into the bigger picture.

### ğŸ”§ Tech Stack Detection & Reasoning
Not just _"this project uses React"_ â€” FirstPR tells you **why**. It parses `package.json`, `requirements.txt`, `pyproject.toml`, `Cargo.toml`, `go.mod`, and more, then explains each dependency's role in the project.

### ğŸ“‹ Beginner-Friendly Issue Ranking
Issues aren't just listed â€” they're **ranked by approachability**. FirstPR analyzes labels, comment volume, and age to surface the issues most suitable for a first-time contributor. Pull requests linked to a selected issue are highlighted in the activity panel.

### ğŸ¥ Community & Repository Health
A full health check: Is the project actively maintained? What's the commit frequency? Are PRs getting reviewed? Does the repo use linters (ESLint, Prettier, Ruff, Black)? Are bots like Dependabot or Renovate configured? FirstPR scores activity as ğŸŸ¢ Active, ğŸŸ¡ Moderate, or ğŸ”´ Abandoned â€” so you know before you invest time.

### ğŸ—ºï¸ Personalized Onboarding Roadmap
A **day-by-day plan** to go from zero to your first pull request. It includes setup commands, key files to read first, and recommended first tasks â€” generated specifically for the repo you're looking at.

### ğŸ’¬ AI Chat Assistant
A floating chat widget that knows the full context of the analyzed repo. Ask it anything: _"Where is authentication handled?"_, _"What testing framework does this use?"_, _"How do I run the dev server?"_ â€” and get answers grounded in the actual codebase, not generic advice.

### ğŸ” CI/CD & Workflow Detection
FirstPR scans for GitHub Actions workflow files and surfaces the project's CI/CD setup â€” so you know what checks your PR needs to pass before you even write a line of code.

All of this rendered in a **dark-themed, three-panel dashboard** â€” file explorer on the left, analysis in the center, activity feed on the right â€” designed to feel like home for any developer.

---

## How We Built It

### The Stack

| Layer | Technology | Role |
|-------|-----------|------|
| **Frontend** | React 19, TypeScript, Vite | SPA with lazy-loaded components |
| **Styling** | TailwindCSS, Framer Motion | Dark GitHub-inspired theme + animations |
| **Diagrams** | Mermaid.js | Renders AI-generated architecture diagrams |
| **Markdown** | react-markdown | Renders README and AI explanations |
| **Backend** | Python, FastAPI, httpx | Async API with connection pooling |
| **AI Engine** | Google Gemini 3 Pro | Architecture analysis, file explanations, chat |
| **Data** | GitHub REST API v3 | Repository metadata, files, issues, PRs |
| **Infra** | Docker, Docker Compose | One-command deployment |

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     POST /analyze      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React UI  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   FastAPI         â”‚
â”‚  (Vite SPA) â”‚ â—„â”€â”€ GET /status â”€â”€â”€â”€â”€  â”‚   Backend         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     (polling)           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â–¼            â–¼            â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ GitHub   â”‚ â”‚ Gemini 3 â”‚ â”‚ Static   â”‚
                              â”‚ API      â”‚ â”‚ Pro API  â”‚ â”‚ Analyzer â”‚
                              â”‚          â”‚ â”‚          â”‚ â”‚ (AST)    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The system follows an **async job-based architecture**:

1. The user pastes a GitHub URL (e.g., `facebook/react`) into the input
2. The backend validates the format, creates an **async analysis job**, and returns a `job_id`
3. The frontend **polls** `GET /analyze/{job_id}/status` for progress updates
4. Meanwhile, the backend orchestrates **concurrent tasks** with a semaphore-controlled pool:
   - **GitHub Client** â€” fetches metadata, recursive file tree, README, issues, PRs, commits, and workflow files (with async LRU caching and exponential backoff for rate limits)
   - **Static Analyzer** â€” detects tech stack from manifest files, parses Python ASTs for function signatures, identifies entry points
   - **Activity Analyzer** â€” computes repository health: days since last commit, 90-day commit frequency, active contributor count, 30-day PR merge rate
   - **Issue/PR Intelligence** â€” ranks issues by beginner-friendliness, analyzes PR review culture and merge patterns
   - **Rules Detector** â€” identifies linting tools, configured bots, and compliance status
   - **LLM Service** â€” sends structured prompts to Gemini 3 Pro, requesting JSON output with project summary, Mermaid architecture diagram, tech stack reasoning, dev workflow commands, and an onboarding roadmap
5. Results are aggregated into a unified `AnalysisResult` and stored
6. The dashboard renders all panels: overview, file explorer, activity feed, and chat

### Key Architectural Decisions

- **Lazy-loaded dashboard** â€” `React.lazy` + `Suspense` so the landing page loads instantly; the heavy dashboard components only load after analysis starts
- **Job-based polling over WebSockets** â€” simpler to deploy on Railway/Render/Fly.io, and analysis is a one-shot operation, not a stream
- **Async LRU caching on GitHub calls** â€” repeated requests for the same repo (e.g., during chat follow-ups) hit cache instead of burning API quota
- **Semaphore-controlled concurrency** â€” max 10 concurrent file fetches to avoid overwhelming the GitHub API while still parallelizing work
- **ProcessPoolExecutor for AST parsing** â€” CPU-bound Python parsing offloaded to a separate process pool (max 4 workers) to keep the async event loop responsive

### The Math Behind Issue Ranking

We rank issues by beginner-friendliness using a weighted scoring model. Given an issue \\( i \\) with comment count \\( c_i \\), label set \\( l_i \\), and age in days \\( d_i \\):

$$
S(i) = w_1 \cdot \frac{1}{1 + c_i} + w_2 \cdot \mathbb{1}[l_i \cap L_{\text{beginner}} \neq \emptyset] + w_3 \cdot \frac{1}{\log(1 + d_i)}
$$

where:
- \\( L_{\text{beginner}} = \\) `{good-first-issue, help-wanted, beginner, easy, starter}` â€” the set of beginner-friendly labels
- \\( w_1 \\) rewards issues with **fewer comments** (less likely to be complex or contentious)
- \\( w_2 \\) boosts issues **explicitly tagged** for newcomers
- \\( w_3 \\) favors **recently opened** issues (more likely to still be relevant)

This ensures new contributors see the **most approachable issues first** â€” not just the newest or most-commented.

---

## Challenges We Faced

### 1. Taming the GitHub API Rate Limit

A single repo analysis can trigger 10â€“20 API calls: metadata, recursive file tree, README content, open issues, pull requests, recent commits, workflow files, and community profile. The GitHub REST API limits unauthenticated requests to **60/hour**. We built the GitHub client with three layers of defense:
- **Token-based auth** (user-provided or system fallback) to push the limit to 5,000/hour
- **Async LRU cache** (32 entries) so repeated requests for the same resource are instant
- **Exponential backoff retry** on 403/429 responses, with jitter to avoid thundering herd

### 2. Getting Gemini 3 to Return Structured Output

We needed Gemini to return **valid JSON** with specific fields: `project_summary`, `architecture_diagram` (valid Mermaid syntax), `tech_stack` (array of objects with `name` and `reason`), `dev_workflow` (setup/test commands), and `onboarding_roadmap` (day-by-day tasks). LLMs love to improvise â€” adding commentary, wrapping JSON in markdown code blocks, or hallucinating extra fields. We iterated through dozens of prompt versions, adding system instructions, explicit schema definitions, and output format examples until Gemini reliably produced parseable, structured output.

### 3. Handling Massive Repositories

Repos like `torvalds/linux` have **70,000+ files**. We can't send the full tree to Gemini â€” it would blow the context window and the API cost. The solution: **intelligent truncation**. The static analyzer samples the top-level structure, prioritizes manifest files (`package.json`, `Cargo.toml`, `go.mod`, `pyproject.toml`), entry points, and README, then builds a representative snapshot. Gemini infers the rest from patterns â€” and it's surprisingly accurate.

### 4. The Cold Start Problem

The first analysis takes 15â€“30 seconds (GitHub API round-trips + Gemini inference). Users staring at a blank screen will bounce. We built a **five-phase loading overlay** with animated progress steps â€” _"Fetching repository dataâ€¦"_, _"Analyzing architectureâ€¦"_, _"Building onboarding roadmapâ€¦"_ â€” each with its own icon and transition animation. It turns a wait into an experience. Users told us it felt like the tool was _working hard for them_, not just loading.

### 5. Making the Chat Actually Useful

The chat assistant isn't a generic chatbot â€” it needs to know the _specific_ repo the user just analyzed. On first open, the ChatWidget loads the full analysis context (project summary, tech stack, file structure, recommended issues) into the conversation history as a system message. Every follow-up question is grounded in that context, so when a user asks _"Where do I find the auth logic?"_, the response references actual file paths from the analyzed repo â€” not generic advice.

---

## What We Learned

- **Prompt engineering is software engineering.** Structured prompts with JSON schemas, output examples, and explicit guardrails are as critical as the application code. A bad prompt produces beautiful nonsense; a good prompt produces reliable, parseable output that drives the entire UI.
- **Developer tools must feel like developer tools.** The dark theme, the three-panel layout, the syntax highlighting, the terminal-inspired loading messages â€” these weren't cosmetic choices. They built instant trust with our target users. When a developer sees a tool that looks like _their_ environment, they lean in instead of bouncing.
- **Open source has an onboarding crisis.** Every developer we showed FirstPR to had the same reaction: _"I wish I had this when I started."_ The problem isn't a lack of willing contributors â€” it's a comprehension gap. Projects lose potential contributors not because the issues are too hard, but because the _codebase_ is too opaque.
- **Caching is a feature, not an optimization.** With GitHub's rate limits and Gemini's latency, aggressive caching wasn't just nice-to-have â€” it was table stakes. The async LRU cache on our GitHub client turned follow-up chat queries from 2-second round-trips into instant responses.

---

## What's Next

- **VS Code Extension** â€” analyze repos directly from your editor without leaving your workflow
- **PR Readiness Checker** â€” before you submit, FirstPR validates your changes against the project's linting rules, test conventions, and CI requirements
- **Team Onboarding Mode** â€” generate onboarding docs for internal company repos, not just public open source
- **Multi-model Support** â€” swap Gemini for Claude, GPT-4, or local models via Ollama depending on your needs and budget

---

## Try It

```bash
# Clone and run with Docker (recommended)
git clone https://github.com/adarshvision1/FirstPR.git
cd FirstPR
docker-compose up --build
# Open http://localhost:3000
```

Or test the analysis engine directly from the command line:

```bash
python backend/firstpr-cli.py analyze facebook/react
```

---

_Built with â˜• and mass frustration at the Gemini 3 Hackathon._
_Because your first PR shouldn't require reading 10,000 lines of code._
